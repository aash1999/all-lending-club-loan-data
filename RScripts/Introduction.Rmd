---
title: "Analysis on LendingClub's Loan Data"
author: "Uyemaa Gantulga, Ayush Meshram, Aakash Singh, and Melissa Yago"
date: "10/20/24"
output:
  html_document:
    code_folding: show
    number_sections: false
    toc: yes
    toc_depth: 3
    toc_float: yes
  pdf_document:
    toc: yes
    toc_depth: '3'
---

```{r setup, include=F}
# Some of common RMD options (and the defaults) are: 
# include=T, eval=T, echo=T, results='hide'/'asis'/'markup',..., collapse=F, warning=T, message=T, error=T, cache=T, fig.width=6, fig.height=4, fig.dim=c(6,4) #inches, fig.align='left'/'center','right', 
knitr::opts_chunk$set(results="markup", warning = F, message = F)
# Can globally set option for number display format.
options(scientific=T, digits = 3) 
# options(scipen=9, digits = 3) 
library(dplyr)
library(ezids)
library(ggplot2)
library(data.table)
library(fmsb)
library(corrplot)
library(lubridate)
library(maps)
library(ggmap)
library(tidyverse)
library(forcats)
library(readr)
library(reshape2)
library(viridis)  
library(ggcorrplot) 
source("./HelperFunctions/fetchSubset.R")
```


```{r}
df <- read.csv("../DataSet/cleaned_accepted_2013_to_2018Q4.csv")
col_names = c("Debt-To-Income Ratio", "Risk_Score","Application Date")
dfr <- fetch_subset(df_location = "../DataSet/filtered_rejected_2013_to_2018Q.csv", col_names = col_names, nrows = c(1,-1))
set.seed(1)  # For reproducibility
dfr <- dfr %>% sample_frac(0.25)

```

# i. Overview

Since 2006, LendingClub has been a U.S. financial services company that has facilitated loan contracts. Our research will focus on LendingClub's loan data that consist of approved and rejected loans between 2013-2018. To understand LendingClubâ€™s clientele, we will analyze borrower and loan characteristics to assess risk levels, determine loan acceptance, and understand what factors influence whether accepted loans will be fully repaid. To accomplish this, we will ask the following SMART questions:


1. How do the loan features of term, amount, and interest rate individually influence the likelihood of a loan being charged off (lender has accepted the loan as unlikely to recover) versus being fully paid? 

2. How do variables such as dti, annual_inc, int_rate, and fico_range impact the likelihood of a loan being "fully paid" or "charged off" year over year from 2014 to 2016? What trends can be identified in the data, and how do these variables differ between the two loan statuses over time?

3. Do the loan grades provided to each customer correlate to their loan repayment behavior based on income and loan status? 

4. Is there a relationship between employment length and the amount requested for rejected loans and how does it compare to the customers that had accepted loans?

# ii. Data Dictionary

1. Funded Amount: The total amount of the loan to be paid off.

2. Loan Status: Whether the loan has been fully paid or has been charged off. A loan that is fully paid is defined as a loan where the total payment has been met. A charge off status is defined as the lender accepting the loan as uncollectible. This differs from the default status in which payments are late but the lender expects to collect what the borrower still owes.  

3. Term: How long the borrower has to pay off the loan (Either 36 or 60 Months).

4. Interest Rate: The percentage of the loan amount that the lender charges the borrower for borrowing money. 

5. DTI (Debt to Income Ratio): A measure used to evaluate a borrower's financial situation by comparing their debt payments to their gross monthly income. 

6. Annual Income: The dollar amount the customer earns on a yearly basis. 

7. FICO Range: A measure of creditworthiness used by lenders to assess a borrower's ability to repay a loan. 

8. Loan Grades: Classifies the risk level of a loan from A (less risky) to G (risky). 

9. Employment Length: The amount in years the customer has been employed. 


# 1. How do the loan features of term, amount, and interest rate individually influence the likelihood of a loan being charged off versus being fully paid? 

This question focuses on assessing risk levels and looking into trends of when the company can expect to see a loan charged off (lender has accepted the loan as unlikely to recover) or being paid off. 

Assumptions:
In terms of loan status, we are only analyzing the "Fully Paid" and "Charge Off" status.

## 1.1 Data Types & Data Cleaning

For this question, we will be looking at funded amount, loan status, term, and interest rate. 

Based on this data, the funded amount and interest rate are data types that are numerical. On the other hand, loan status and term have been converted to factors and are categorical data types. While loan status logically makes sense to be categorical, term has been converted to a factor since there were only two types of loan terms (36 or 60 months) which can be seen as short term vs. long term when comparing the likelihood of default across loans. Term in this case will be viewed as nonlinear with interest rates and funded amount affecting risk with linearity.

To retrieve this information, data cleaning was done on the accepted loans dataset that initially contained 2,157,894 million observations. After filtering, the total observations stand at 1,245,285 observations.    


```{r, echo=TRUE}

#Subset for Specific Columns
f_df<- df[, c("funded_amnt", "loan_status","term","int_rate")]

#Filter for specific loan status
df_filter <- f_df %>%
  filter(loan_status %in% c("Charged Off", "Fully Paid"))

rm(f_df)

#Convert loan status and term as factors
df_filter$loan_status <- as.factor(df_filter$loan_status)
df_filter$term <- as.factor(df_filter$term)


#Select Relevant Columns
df_final <-df_filter %>%
  select(funded_amnt, term, int_rate, loan_status)

rm(df_filter)
#Check the Dataframe output
str(df_final)



```

## 1.2 Normality of Loan Amount & Interest Rate

### 1.2.1 QQ Plot of Loan Amount

```{r, echo=TRUE}

amount_plot = outlierKD2(df_final, funded_amnt, rm = TRUE, qqplt = TRUE, histogram = FALSE)
rm(amount_plot)

```

The loan amount data does not appear to follow a normal distribution based on the QQ plot, as there are significant deviations from the reference line, particularly at the tails. The lower quantiles fall below the line, while the upper quantiles rise far above it, indicating the presence of heavy tails. Additionally, the stepped line in the middle suggests that the data isn't evenly distributed. Even with the outliers removed, there are still extreme deviations at both ends therefore showing that this is not a normal distribution.    

### 1.2.2 QQ Plot of Interest Rate


```{r, echo=TRUE}

rate_plot = outlierKD2(df_final, int_rate, rm = TRUE, qqplt = TRUE, histogram = FALSE)
rm(rate_plot)

```

The interest rate also shows similar trends. There are major deviations from the reference line, especially in the upper tail, indicating that the interest rate distribution is not normal when outliers are present. Even with the outliers removed, the QQ plot appears much more linear showing significant improvement towards normality, though there are deviations that remain in the tails. 

Overall, both loan amount and interest rate distributions are not normal when outliers are included. While showing improvement in normality when removing outliers, deviations still occur at the extremes. As a result, these datasets don't follow normality due to these deviations. 

## 1.3 Descriptive Statistics

Initial statistics summarizes data that can help in identifying patterns, trends, and outliers. To demonstrate this, loan status will be analyzed against each loan feature (term, amount and interest rate) to see any relationships and patterns.  

### 1.3.1 Relationship between Loan Status and Loan Term

```{r, echo=TRUE}


# Contingency Table (Correlation Analysis)
c_table <- table(df_final$term, df_final$loan_status)
cat("Contingency Table: Loan Status by Term\n\n")
print(c_table)

#Contingency Table by Proportions
prop_table <-prop.table(c_table) *100
cat("Contingency Table: Loan Status by Term Proportions (by %)\n\n")
print(prop_table)
rm(c_table)
# Stacked Bar Chart
ggplot(df_final, aes(x = term, fill = loan_status)) + 
  geom_bar(position = "stack") +
  labs(x="Loan Term", y="Number of Loans",title="Stacked Bar Chart of Loan Status by Term" ) +
  scale_fill_manual(values = c("navy", "lightblue"))

  
```

Via the first contingency table, 36 month loans have a higher absolute number of both fully paid and charged off loans compared to 60 month loans. Proportionally, 36 month loans have a higher rate of being charged off (12.32%) than 60 month loans (8.01%).

When visually shown on a stacked bar chart, you'll notice that shorter terms are more likelier to get charged off than loans with a longer term.  

Overall, shorter loan terms are likelier to result in a charge off and appear to influence loan status. 


### 1.3.1 Relationship between Loan Status and Loan Amount

```{r, echo=TRUE}
# Descriptive Stats of Loan Amount Separated by Loan Status

amnt_stats <- df_final %>%
  group_by(loan_status) %>%
  summarise(
    Mean = mean(funded_amnt, na.rm = TRUE),
    Median = median(funded_amnt, na.rm = TRUE),
    SD = sd(funded_amnt, na.rm = TRUE),
    Q25 = quantile(funded_amnt, 0.25, na.rm = TRUE),
    Q50 = quantile(funded_amnt, 0.50, na.rm = TRUE),
    Q75 = quantile(funded_amnt, 0.75, na.rm = TRUE),
    Min = min(funded_amnt, na.rm = TRUE),
    Max = max(funded_amnt, na.rm = TRUE)
  )

cat("Descriptive Stats of Loan Amounts Separated by Loan Status)\n\n")
print(amnt_stats)
rm(amnt_stats)

```

```{r, echo=TRUE}
# Box Plot Comparing Loan Amounts by Loan Status
ggplot(df_final, aes(x = loan_status, y=funded_amnt, fill = loan_status)) + 
  geom_boxplot() + 
  geom_boxplot( colour="black", outlier.colour="blue", outlier.shape=8, outlier.size=4) +
  labs(title="Boxplot of Loan Amounts by Loan Status", x="Loan Status", y = "Loan Amount ($)")+ 
  scale_fill_manual(values = c("navy", "lightblue"))

```

Based on the statistics, the charged off loans having a higher mean and median loan amount, this can suggest that larger loan amounts may be associated with a higher risk of being charged off. Charged off loans also have a slightly higher standard deviation showing for more variability in the amounts.Lastly, both loan statuses show the same minimum and maximum but that does not necessarily mean that the distributions are identical.

Based on the boxplot, one commonality is the several outliers that exist around $40,000 for both loan statuses. However, this is not indicative that it is caused by status and requires further investigation through these high amounts being affected by other factors. Given the IQR of both statuses, there is not significant variability. You can however tell based on the IQR that the charged off loans have a slightly higher loan amounts compared to the fully paid loans that have a slightly lower loan amount.

Overall, larger loan amounts may be associated with a higher charged off risk. However holistically, loan amount alone does not appear to have a strong influence on whether a loan will be charged off or fully paid, given overlapping distributions. 


### 1.3.2 Relationship Between Loan Status and Interest Rate

```{r, echo=TRUE}
# Descriptive Stats of Interest Rate Separated by Loan Status

rate_stats <- df_final %>%
  group_by(loan_status) %>%
  summarise(
    Mean = mean(int_rate, na.rm = TRUE),
    Median = median(int_rate, na.rm = TRUE),
    SD = sd(int_rate, na.rm = TRUE),
    Q25 = quantile(int_rate, 0.25, na.rm = TRUE),
    Q50 = quantile(int_rate, 0.50, na.rm = TRUE),
    Q75 = quantile(int_rate, 0.75, na.rm = TRUE),
    Min = min(int_rate, na.rm = TRUE),
    Max = max(int_rate, na.rm = TRUE)
  )

cat("Descriptive Stats of Interest Rates Separated by Loan Status)\n\n")
print(rate_stats)
rm(rate_stats)

```

```{r, echo=TRUE}

df_count <-df_final %>%
  filter(int_rate >0) %>%
  mutate(int_rate_bin = floor(int_rate/2)*2) %>%
  filter(int_rate_bin >0) %>%
  count(int_rate_bin, loan_status)

ggplot(df_count, aes(x = int_rate_bin, y = n, color = loan_status)) + 
  geom_line(size = 1)+ 
  labs(x="Interest Rate (%)", y="Count", title = "Distribution of Interest Rates by Loan Status") +
  scale_color_manual(values = c("navy", "lightblue")) 

rm(df_count)
rm(df_final)
```

Based on the statistics, higher interest rates significantly increase the likelihood of a loan being charged off. Charged off loans have a mean interest rate of 15.8%, compared to 12.6% for fully paid loans, with a similar difference in the median (15.1% vs. 12.1%). Even at the lower end of the interest rate range, loans that default tend to have higher rates. As charged off loans have a higher standard deviation and higher 75th percentile, this suggests greater volatility and risk. This indicates that interest rates are a strong predictor of loan defaults.  

Similar to the statistics, the histogram shows interest rates having a strong influence on loan outcomes. Loans with a higher interest rate of around 15% and above are more likely to be charged off (in proportion to fully paid), indicating a greater risk of default at these levels. In contrast, lower interest rates between 10% to 12% are associated with a higher frequency of fully paid loans, suggesting that borrowers with lower rates are more likely to repay their loans in full. There is also a noticeable overlap in the 10% to 15% interest rate range, where fully paid and charged off loans occur. But as interest rates increase, the likelihood of a loan being charged off rises significantly. This suggests that interest rates are a key predictor of loan performance, with higher rates correlating strongly with loan defaults and lower rates with successful repayment.  

Overall, loans with higher interest rates are likelier to be charged off, making interest rates a strong influence of loan charge offs. 


```{r}
columns_to_target = c("annual_inc", "dti", "fico_range_high", "fico_range_low", "loan_amnt", 
  "int_rate", "earliest_cr_line", "revol_util", "delinq_2yrs", "pub_rec", 
  "total_acc", "open_acc", "installment", "home_ownership", 
  "verification_status", "delinq_amnt", "collections_12_mths_ex_med", 
  "chargeoff_within_12_mths", "mths_since_last_delinq", "purpose", "sub_grade", "issue_d", "addr_state","inq_last_12m","loan_status","chargeoff_within_12_mths")


#df <- fetch_subset(df_location = df_file_path, col_names = columns_to_target, nrows = c(1,-1))
df_final <- df %>% select(all_of(columns_to_target))


convert_to_factors <- function(df) {
  # Columns to convert to factors based on the provided list
  factor_cols <- c("home_ownership", "verification_status", 
                   "loan_status", "purpose", "addr_state","sub_grade")
  
  df[] <- lapply(names(df), function(col) {
    if (col %in% factor_cols) {
      # Check if the column contains numeric-like values as strings and standardize them
      if (col == "chargeoff_within_12_mths") {
        # Convert '0.0' and '0' to '0', and handle similar cases
        df[[col]] <- as.character(df[[col]])
        df[[col]][df[[col]] == "0.0"] <- "0"
        df[[col]][df[[col]] == "1.0"] <- "1"  # If applicable, handle '1.0' similar to '1'
        return(as.factor(df[[col]]))  # Convert the cleaned column to factor
      } else {
        return(as.factor(df[[col]]))  # Convert other factor columns directly
      }
    } else if (is.character(df[[col]]) && all(!is.na(as.numeric(df[[col]][-1])))) {
      return(as.numeric(df[[col]]))  # Convert numeric-like strings to numeric
    } else {
      return(df[[col]])  # Leave other columns unchanged
    }
  })
  
  return(df)
}
df_final <- df_final[-1,]
df_final <- convert_to_factors(df_final)
#str(df_final)

# Convert specified columns to numeric

df_final$revol_util <- as.numeric(df_final$revol_util)
df_final$mths_since_last_delinq <- as.numeric(df_final$mths_since_last_delinq)
df_final$dti <- as.numeric(df_final$dti)
df_final$inq_last_12m <- as.numeric(df_final$inq_last_12m)
df_final$chargeoff_within_12_mths <- as.numeric(df_final$chargeoff_within_12_mths)

# Optional: Check for any warnings about NAs being introduced during coercion
if (any(is.na(df_final$revol_util))) {
  warning("NAs introduced in 'revol_util' during conversion.")
}
if (any(is.na(df_final$mths_since_last_delinq))) {
  warning("NAs introduced in 'mths_since_last_delinq' during conversion.")
}
if (any(is.na(df_final$dti))) {
  warning("NAs introduced in 'dti' during conversion.")
}


df_final$issue_d <- as.Date(df_final$issue_d, format = "%Y-%m-%d")
```

# 2 How do variables such as dti, annual_inc, int_rate, and fico_range impact the likelihood of a loan being fully paid or charged off year over year from 2013 to 2018? What trends can be identified in the data, and how do these variables differ between the two loan statuses over time?

## 2.1 Analysis of Charged-Off Loan Percentage (2013-2018)


```{r}
# LINE PLOT

# Create a copy of the dataframe
df1 <- df_final

# Step 1: Ensure 'issue_d' is in Date format
df1$issue_d <- as.Date(df1$issue_d, format = "%Y-%m-%d")  # Adjust the format if necessary

# Step 2: Extract year and quarter from 'issue_d'
df1 <- df1 %>%
  mutate(year = year(issue_d), 
         quarter = quarter(issue_d))

# Step 3: Filter out rows with NA values in year or quarter
df1 <- df1 %>%
  filter(!is.na(year), !is.na(quarter))

# Step 4: Calculate the total number of loans per quarter
df_total_per_quarter <- df1 %>%
  group_by(year, quarter) %>%
  summarise(total_loans = n(), .groups = 'drop')  # Adding .groups = 'drop' to avoid warnings

# Step 5: Filter for 'Charged Off' loan status
df_charged_off <- df1 %>%
  filter(loan_status == "Charged Off")

# Step 6: Aggregate 'Charged Off' counts by year and quarter
df_charged_off_aggregated <- df_charged_off %>%
  group_by(year, quarter) %>%
  summarise(charged_off_count = n(), .groups = 'drop')  # Adding .groups = 'drop' to avoid warnings

# Step 7: Merge the total loan counts with the 'Charged Off' counts
df_merged <- df_charged_off_aggregated %>%
  left_join(df_total_per_quarter, by = c("year", "quarter")) %>%
  mutate(percentage = (charged_off_count / total_loans) * 100)

# Step 8: Create a Year-Quarter variable in the correct format and order
df_merged <- df_merged %>%
  mutate(Year_Quarter = paste0(year, ".", quarter)) %>%
  arrange(year, quarter)  # Arrange the data to ensure it's in the correct order

# Step 9: Convert Year_Quarter into a factor with levels in the correct chronological order
df_merged$Year_Quarter <- factor(df_merged$Year_Quarter, 
                                 levels = df_merged$Year_Quarter)

# Step 10: Create the line plot with percentage and display percentage as text on each point
ggplot(df_merged, aes(x = Year_Quarter, y = percentage, group = 1)) +
  geom_area(fill = "red", alpha = 0.3) +  # Fill the area under the line with color and adjust opacity
  geom_line(color = "red", size = 1) +  # Line color and size
  geom_point(color = "red", size = 2) +  # Point color and size
  geom_text(aes(label = sprintf("%.1f%%", percentage)), 
            vjust = -0.5, size = 3, nudge_y = 0.5) +  # Display percentage above points
  labs(x = "Year-Quarter", y = "Charged Off Percentage", title = "Percentage of Charged Off Loans by Year and Quarter") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1),  # Rotate x-axis labels
        panel.grid.major.y = element_blank(),  # Remove horizontal grid lines
        panel.grid.minor.y = element_blank())  # Remove minor horizontal grid lines


rm(df_charged_off)
rm(df1)
rm(df_charged_off_aggregated)
rm(df_merged)
rm(df_total_per_quarter)

```

The charged-off percentage increases from Q1 2013 (14.9%) to Q2 2015 (18.5%), then decreases drastically until Q4 2018. There could be two explanations for this decline:

   - Lenders may have changed their loan selection parameters.
   - Since most loan tenures exceed three years, some active loans might charge off in the future (after 2018), for which we don't have data.


## 2.2 Hypothesis Testing for Key Financial Features

```{r}
# T-test

# Ensure you're using the tidyverse for complete functionality
# Uncomment the following line if you want to load the entire tidyverse
# library(tidyverse)

# Step 1: Verify and convert 'issue_d' to Date if necessary
df_final$issue_d <- as.Date(df_final$issue_d, format = "%Y-%m-%d")  # Adjust the format if necessary

# Step 2: Filter the dataframe for 'Charged Off' loan_status and remove NaN values
charged_off_df <- df_final %>%
  filter(loan_status == "Charged Off") %>%
  filter(!is.na(issue_d))  # Ensure we have dates to work with

# Step 3: Create a new column for quarters if not already created
charged_off_df <- charged_off_df %>%
  mutate(quarter = quarter(issue_d), 
         year = year(issue_d),
         quarter_year = as.integer(format(issue_d, "%Y")) * 10 + ceiling(as.integer(format(issue_d, "%m")) / 3))

# Step 4: Check unique quarters available in the dataset
unique_quarters <- unique(charged_off_df$quarter_year)
#cat("Unique quarters in the dataset:", unique_quarters, "\n")

# Step 5: Split the data into two groups: before and including Q2 2015, and after Q2 2015
before_2015_Q2 <- charged_off_df %>%
  filter(year < 2015 | (year == 2015 & quarter <= 2))

after_2015_Q2 <- charged_off_df %>%
  filter(year > 2015 | (year == 2015 & quarter > 2))



# Proceed only if there are records in both groups
if (nrow(before_2015_Q2) > 0 && nrow(after_2015_Q2) > 0) {
  # Step 6: Identify numerical features in the filtered dataframe
  numerical_cols <- before_2015_Q2 %>%
    select_if(is.numeric) %>%
    colnames()

  # Step 7: Perform T-test for each numeric column, excluding those with zero observations in either group
  alpha <- 0.05  # Significance level
  t_test_results <- lapply(numerical_cols, function(col) {
    # Extract the two groups
    group1 <- before_2015_Q2[[col]]
    group2 <- after_2015_Q2[[col]]

    # Check if both groups have enough non-NA observations
    if (length(na.omit(group1)) > 0 && length(na.omit(group2)) > 0) {
      # Perform the t-test
      t_test_result <- t.test(group1, group2, var.equal = FALSE)  # Welch's t-test

      # Determine hypothesis status
      hypothesis_status <- ifelse(t_test_result$p.value <= alpha, "Reject H0", "Fail to Reject H0")

      return(data.frame(Feature = col, T_value = t_test_result$statistic, P_value = t_test_result$p.value, Hypothesis_Status = hypothesis_status))
    } else {
      return(NULL)  # Return NULL for insufficient data
    }
  })

  # Step 8: Remove NULL results and combine results into a dataframe
  t_test_results_df <- do.call(rbind, Filter(Negate(is.null), t_test_results))
  
  # Step 9: Remove unwanted features
  t_test_results_filtered <- t_test_results_df %>%
    filter(!Feature %in% c("quarter", "year", "quarter_year"))
  
  # Step 10: Print the filtered results
  print(t_test_results_filtered)

} else {
  cat("Not enough records in one of the groups to perform t-tests.\n")
}
rm(after_2015_Q2)
rm(before_2015_Q2)
rm(charged_off_df)
rm(t_test_results)
rm(t_test_results_df)
rm(t_test_results_filtered)


```

- **Annual Income (annual_inc)**: 
  - T-value = -14.29, P-value = 2.66e-46
  - **Result**: Reject H0
  - Interpretation: Significant difference in annual income, indicating that it is a key feature for loan outcomes.

- **Debt-to-Income Ratio (dti)**: 
  - T-value = -20.26, P-value = 3.66e-91
  - **Result**: Reject H0
  - Interpretation: Significant difference in debt-to-income ratio, suggesting its importance in distinguishing loan status.

- **FICO Range High (fico_range_high)** and **FICO Range Low (fico_range_low)**: 
  - T-value = -21.90, P-value = 3.33e-106 (high), 3.32e-106 (low)
  - **Result**: Reject H0
  - Interpretation: Both FICO score ranges are critical indicators of loan status.

- **Loan Amount (loan_amnt)**: 
  - T-value = -1.84, P-value = 6.65e-02
  - **Result**: Fail to Reject H0
  - Interpretation: No significant difference in loan amount with respect to loan outcomes.

- **Interest Rate (int_rate)**: 
  - T-value = 7.60, P-value = 2.99e-14
  - **Result**: Reject H0
  - Interpretation: Interest rate is a significant differentiator in loan status.

- **Revolving Utilization (revol_util)**: 
  - T-value = 65.33, P-value = 0.00e+00
  - **Result**: Reject H0
  - Interpretation: Strong influence of revolving utilization on loan status.

- **Delinquencies in 2 Years (delinq_2yrs)**: 
  - T-value = -6.79, P-value = 1.11e-11
  - **Result**: Reject H0
  - Interpretation: Significant impact of past delinquencies on loan status.

- **Public Records (pub_rec)**: 
  - T-value = -18.93, P-value = 7.76e-80
  - **Result**: Reject H0
  - Interpretation: Public records significantly affect loan outcomes.

- **Total Accounts (total_acc)**: 
  - T-value = 21.91, P-value = 2.49e-106
  - **Result**: Reject H0
  - Interpretation: The total number of accounts plays a critical role in determining loan status.

- **Open Accounts (open_acc)**: 
  - T-value = -6.28, P-value = 3.30e-10
  - **Result**: Reject H0
  - Interpretation: Number of open accounts significantly influences loan status.

- **Installment Amount (installment)**: 
  - T-value = -16.88, P-value = 6.75e-64
  - **Result**: Reject H0
  - Interpretation: Installment amount is a significant factor in loan status differentiation.

- **Delinquency Amount (delinq_amnt)**: 
  - T-value = -4.22, P-value = 2.42e-05
  - **Result**: Reject H0
  - Interpretation: Past delinquency amounts significantly impact loan status.

- **Collections in 12 Months (collections_12_mths_ex_med)**: 
  - T-value = -15.26, P-value = 1.42e-52
  - **Result**: Reject H0
  - Interpretation: The number of collections in 12 months is a key feature influencing loan status.

- **Charge-off within 12 Months (chargeoff_within_12_mths)**: 
  - T-value = -2.94, P-value = 3.32e-03
  - **Result**: Reject H0
  - Interpretation: Significant difference in charge-off occurrences within 12 months.

- **Months Since Last Delinquency (mths_since_last_delinq)**: 
  - T-value = 1.18, P-value = 2.39e-01
  - **Result**: Fail to Reject H0
  - Interpretation: No significant difference in months since the last delinquency.


## 2.3 Correlation Plot Analysis
```{r}
#COOR PLOT

# Load necessary libraries

setDT(df_final)  # Converts df to a data.table, if it isn't one already

# Select only numeric columns from the data table
numeric_df <- df_final[, .SD, .SDcols = sapply(df_final, is.numeric)]

# Calculate the correlation matrix
cor_matrix <- cor(numeric_df, use = "pairwise.complete.obs")
# Set plotting parameters for larger plot size
# Create a larger plot window
options(repr.plot.width = 35, repr.plot.height = 45)  # Use this in RMarkdown or Jupyter Notebooks

# Plot the correlation matrix using corrplot without the title
corrplot(cor_matrix,
         type = "upper", 
         method = "circle", 
         addCoef.col = 0.2,  # Color for coefficients
         number.cex = 0.1,  # Size of the correlation coefficients
         tl.cex = 0.6,      # Size of the text labels for variables
         tl.col = "black",  # Color of the text labels
         cl.cex = 0.5)      # Size of the color legend text

# Remove numeric_df
rm(numeric_df)
rm(cor_matrix)

```

- **Income and Loan Characteristics**: 
  - `annual_inc` has a moderate positive correlation with `loan_amnt` (0.1949) and `installment` (0.188), suggesting that individuals with higher income tend to take larger loans with higher installments.
  - `dti` has a weak positive correlation with `int_rate` (0.1239), indicating a slight increase in interest rates for borrowers with higher debt-to-income ratios.

- **Credit Score Indicators**:
  - `fico_range_high` and `fico_range_low` have strong negative correlations with `int_rate` (-0.4049), indicating that better credit scores are associated with lower interest rates.
  - `fico_range_high` and `fico_range_low` are negatively correlated with `revol_util` (-0.4747), suggesting that individuals with higher credit scores tend to have lower revolving credit utilization.

- **Delinquency Metrics**:
  - `delinq_2yrs` has a strong negative correlation with `mths_since_last_delinq` (-0.5524), indicating that more recent delinquencies are associated with a higher number of delinquencies in the past two years.
  - `pub_rec` shows a weak negative correlation with `loan_amnt` (-0.0628), suggesting a slight decrease in loan amounts with higher public records of delinquencies.

- **Open Accounts and Total Accounts**:
  - `total_acc` and `open_acc` are highly correlated (0.7199), which is expected as they both measure account quantities in credit reports.
  - `total_acc` has a weak positive correlation with `loan_amnt` (0.1966), indicating that borrowers with more accounts tend to have slightly higher loan amounts.

## 2.4 Analysis of Charged-Off Loans by State

```{r}
# US MAP

# Load the state coordinates
state_coords <- read.csv("../DataSet/states.csv")

# Step 1: Verify and convert 'issue_d' to Date if necessary
df_final$issue_d <- as.Date(df_final$issue_d, format = "%Y-%m-%d")  # Adjust the format if necessary

# Step 2: Filter the dataframe and remove NaN values
charged_off_df <- df_final %>%
  filter(!is.na(issue_d), !is.na(addr_state))  # Ensure we have dates and states to work with

# Step 3: Create a new column for quarters
charged_off_df <- charged_off_df %>%
  mutate(quarter_year = as.integer(format(issue_d, "%Y")) * 10 + ceiling(as.integer(format(issue_d, "%m")) / 3))

# Step 4: Split the data into two groups: before and including Q2 2015, and after Q2 2015
before_2015_Q2 <- charged_off_df %>%
  filter(quarter_year <= 20152)

after_2015_Q2 <- charged_off_df %>%
  filter(quarter_year > 20152)

# Step 5: Calculate total loans and charged off loans by state for both periods
total_loans_before <- before_2015_Q2 %>%
  group_by(addr_state) %>%
  summarise(total_loans = n(), .groups = "drop")

charged_off_loans_before <- before_2015_Q2 %>%
  filter(loan_status == "Charged Off") %>%
  group_by(addr_state) %>%
  summarise(charged_off_loans = n(), .groups = "drop")

total_loans_after <- after_2015_Q2 %>%
  group_by(addr_state) %>%
  summarise(total_loans = n(), .groups = "drop")

charged_off_loans_after <- after_2015_Q2 %>%
  filter(loan_status == "Charged Off") %>%
  group_by(addr_state) %>%
  summarise(charged_off_loans = n(), .groups = "drop")

# Step 6: Merge totals and charged off loans for both periods
frequency_data_before <- total_loans_before %>%
  left_join(charged_off_loans_before, by = "addr_state") %>%
  mutate(charged_off_loans = ifelse(is.na(charged_off_loans), 0, charged_off_loans),
         percentage_charged_off = (charged_off_loans / total_loans) * 100)

frequency_data_after <- total_loans_after %>%
  left_join(charged_off_loans_after, by = "addr_state") %>%
  mutate(charged_off_loans = ifelse(is.na(charged_off_loans), 0, charged_off_loans),
         percentage_charged_off = (charged_off_loans / total_loans) * 100)

# Step 7: Merge both frequency data with state coordinates
frequency_data <- state_coords %>%
  left_join(frequency_data_before %>% select(addr_state, percentage_charged_off) %>% rename(percentage_charged_off_before = percentage_charged_off), 
            by = c("state" = "addr_state")) %>%
  left_join(frequency_data_after %>% select(addr_state, percentage_charged_off) %>% rename(percentage_charged_off_after = percentage_charged_off), 
            by = c("state" = "addr_state"))



# Step 8: Filter to keep only points within the contiguous US
frequency_data <- frequency_data %>%
  filter(latitude >= 24.396308 & latitude <= 49.384358 & 
         longitude >= -125.0 & longitude <= -66.93457)

# Step 9: Create the map
us_map <- map_data("state")
# Step 10: Plot with state symbols
ggplot() +
  # Base map
  geom_polygon(data = us_map, aes(x = long, y = lat, group = group), fill = "lightgrey") +
  
  # Points for charged off loans before Q2 2015
  geom_point(data = frequency_data, 
             aes(x = longitude, y = latitude, 
                 size = percentage_charged_off_before, 
                 color = "Before Q2 2015"), 
             alpha = 0.5) +
  
  # Points for charged off loans after Q2 2015
  geom_point(data = frequency_data, 
             aes(x = longitude, y = latitude, 
                 size = percentage_charged_off_after, 
                 color = "After Q2 2015"), 
             alpha = 0.5) +
  
  # Add state abbreviations
  geom_text(data = frequency_data, aes(x = longitude, y = latitude, label = state), 
            color = "black", size = 3, vjust = -0.8) +  # Adjust text size and position
  
  # Adjust the size scale
  scale_size_continuous(
    range = c(3, 10),  # Adjusting the size range
    name = "Percentage of Charged Off Loans"
  ) +
  
  # Define color scale
  scale_color_manual(values = c("Before Q2 2015" = "red", "After Q2 2015" = "green"),
                     name = "Time Period") +
  
  # Labels and title
  labs(title = "Percentage of Charged Off Loans by State (Before and After Q2 2015)",
       x = "Longitude",
       y = "Latitude") +
  
  theme_minimal() +
  theme(legend.position = "top")  # Place legend at the top

rm(after_2015_Q2)
rm(before_2015_Q2)
rm(charged_off_df)
rm(charged_off_loans_after)
rm(charged_off_loans_before)
rm(us_map)
rm(frequency_data)
rm(frequency_data_after)
rm(state_coords)
rm(total_loans_after)
rm(total_loans_before)
rm(frequency_data_before)

```

- **Iowa (IA)**:
  - **Before**: 50.0%
  - **After**: NA
  - **Insight**: The charged-off percentage was significantly high before the intervention, but data for after the intervention is not available, indicating a potential area for further investigation.

- **Nebraska (NE)**:
  - **Before**: 50.0%
  - **After**: 11.51%
  - **Insight**: A substantial decrease from 50.0% to 11.51%, indicating a successful intervention that significantly improved loan performance.

- **Florida (FL)**:
  - **Before**: 18.6%
  - **After**: 10.52%
  - **Insight**: A notable decrease of 8.08 percentage points, suggesting a positive impact of the intervention.

- **Mississippi (MS)**:
  - **Before**: 21.4%
  - **After**: 11.87%
  - **Insight**: The charged-off percentage decreased by 9.53 percentage points, indicating improved loan performance.

- **California (CA)**:
  - **Before**: 16.9%
  - **After**: 10.32%
  - **Insight**: A reduction of 6.58 percentage points, demonstrating effective measures in managing loan defaults.

The analysis highlights states like Nebraska and Iowa as significant cases with varying outcomes in charged-off loans. The successful interventions in Nebraska indicate that targeted strategies can yield substantial improvements in loan performance.

## 2.5 Comparison of Debt-to-Income Ratios: Charged-Off vs. Fully Paid Loans (2013-2018)

```{r}

# BOX PLOT

df1 <- df_final
# Ensure issue_d is in Date format
df1$issue_d <- as.Date(df1$issue_d, format = "%b-%Y")

# Filter out rows where issue_d is NA
df1 <- df1 %>%
  filter(!is.na(issue_d))

# Extract year and quarter from issue_d
df1$quarter <- paste0("Q", quarter(df1$issue_d), " ", year(df1$issue_d))

# Filter the data for only "Charged Off" and "Fully Paid" loan statuses
df_filtered <- df1 %>%
  filter(loan_status %in% c("Charged Off", "Fully Paid"))

# Define a function to remove outliers based on IQR
remove_outliers <- function(data) {
  Q1 <- quantile(data$dti, 0.25, na.rm = TRUE)
  Q3 <- quantile(data$dti, 0.75, na.rm = TRUE)
  IQR <- Q3 - Q1
  lower_bound <- Q1 - 1.5 * IQR
  upper_bound <- Q3 + 1.5 * IQR
  data %>%
    filter(dti >= lower_bound & dti <= upper_bound)
}

# Remove outliers by applying the function to each quarter and loan_status group
df_no_outliers <- df_filtered %>%
  group_by(quarter, loan_status) %>%
  do(remove_outliers(.))

# Ensure proper order of quarters
df_no_outliers$quarter <- factor(df_no_outliers$quarter, 
                                 levels = unique(df_no_outliers$quarter[order(df_no_outliers$issue_d)]))

# Plot box plot for dti for each quarter with loan_status distinction (without outliers)
ggplot(df_no_outliers, aes(x = quarter, y = dti, fill = loan_status)) +
  geom_boxplot() +
  labs(title = "DTI Box Plot by Quarter for Charged Off and Fully Paid Loans (Outliers Removed)",
       x = "Quarter",
       y = "DTI",
       fill = "Loan Status") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))  # Rotate x-axis labels for readability
rm(df_filtered)
rm(df1)
rm(df_no_outliers)
rm(expected_counts)
rm(chi_sq_result)


```

- **Median DTI Comparison**: Each quarter, the median DTI for charged-off applicants is higher compared to fully paid applicants, with an average difference of 4.3%.
- **Trends Over Time**: The medians of DTI show an upward trend toward 2015, followed by a slight decrease until 2018.

The analysis indicates that higher DTI ratios are associated with charged-off loans, suggesting a potential risk factor for loan defaults. The observed trends in DTI medians may warrant further investigation to understand the underlying causes.



## 2.6 Radar Chart Analysis of Loan Characteristics (2014 vs. 2018)
```{r}
# RADAR CHART

# Step 1: Filter DataFrames for loans issued in 2014 and 2017
df_2014 <- df_final[df_final$issue_d >= as.Date("2015-01-01") & df_final$issue_d <= as.Date("2015-12-31"), ]
df_2017 <- df_final[df_final$issue_d >= as.Date("2018-01-01") & df_final$issue_d <= as.Date("2018-12-31"), ]

# Step 2: Function to remove outliers using IQR
# Function to remove outliers using IQR method
remove_outliers <- function(df, columns) {
  for (col in columns) {
    if (col %in% names(df)) {
      Q1 <- quantile(df[[col]], 0.25, na.rm = TRUE)
      Q3 <- quantile(df[[col]], 0.75, na.rm = TRUE)
      IQR_value <- IQR(df[[col]], na.rm = TRUE)
      
      # Define lower and upper bounds
      lower_bound <- Q1 - 1.5 * IQR_value
      upper_bound <- Q3 + 1.5 * IQR_value
      
      # Filter out the outliers
      df <- df[df[[col]] >= lower_bound & df[[col]] <= upper_bound, ]
    } else {
      message(paste("Column", col, "not found in the dataframe. Skipping."))
    }
  }
  return(df)
}

# Step 3: Select the columns of interest for standardization and outlier removal
selected_columns <- c("int_rate", "annual_inc", "fico_range_low", "fico_range_high", "dti")
# Remove outliers in each group
df_2014 <- remove_outliers(df_2014, selected_columns)
df_2017 <- remove_outliers(df_2017, selected_columns)

# Step 4: Function to standardize numeric columns (scaling from 0 to 1)
# Convert df_2014 to a data.table
setDT(df_2014)
setDT(df_2017)

# Define the standardization function using data.table syntax
standardize_columns <- function(dt, selected_cols) {
  dt[, (selected_cols) := lapply(.SD, function(x) (x - min(x, na.rm = TRUE)) / 
                                               (max(x, na.rm = TRUE) - min(x, na.rm = TRUE))), 
       .SDcols = selected_cols]
  return(dt)
}


# Standardize the selected columns in each group
df_2014 <- standardize_columns(df_2014, selected_columns)
df_2017 <- standardize_columns(df_2017, selected_columns)

# Step 5: Calculate the medians for selected numeric columns
medians_2014 <- df_2014[, lapply(.SD, median, na.rm = TRUE), .SDcols = selected_columns]
medians_2017 <- df_2017[, lapply(.SD, median, na.rm = TRUE), .SDcols = selected_columns]

# Step 6: Combine the medians into a data frame for radar chart
radar_data_2014_2017 <- rbind(as.data.frame(medians_2014), 
                               as.data.frame(medians_2017))

# Step 7: Assign appropriate row names for each category
rownames(radar_data_2014_2017) <- c("2014", "2017")

# Step 8: Add max and min rows for radar chart
radar_data_2014_2017 <- rbind(max = rep(1, ncol(radar_data_2014_2017)), 
                               min = rep(0, ncol(radar_data_2014_2017)), 
                               radar_data_2014_2017)

# Set the background color to white
par(bg = "white")  
# Step 9: Plot the radar chart for 2014 and 2017
radarchart(radar_data_2014_2017, 
           axistype = 1,  # Set axis type
           pcol = c("#1E90FF", "#32CD32"),  # Brighter line colors for 2014 and 2017
           plty = 1,  # Line type
           title = "Comparison of Loan Variables (2014 vs. 2017)",
           cglcol = "lightgrey",  # Lighter grid line color
           cglty = 1,  # Type of the grid lines
           caxislabels = seq(0, 1, 0.1),  # Customize axis labels (0 to 1 range)
           axislabcol = "black",  # Axis label color
           vlcex = 0.8,  # Text size of labels
           titlecol = "black",  # Title color
           cglwd = 0.8)  # Thickness of the grid lines

# Step 10: Add legend to the radar chart
legend("topright",  # Position of the legend
       legend = c("2014", "2017"),  # Labels for the legend
       col = c("#1E90FF", "#32CD32"),  # Corresponding bright colors
       lty = 1,  # Line type in the legend
       bty = "n",  # No box around the legend
       text.col = "black",  # Text color for the legend
       cex = 0.8)  # Text size of the legend
rm(df_2014)
rm(df_2017)
rm(medians_2014)
rm(medians_2017)
rm(radar_data_2014_2017)

```

- **Interest Rate (int_rate):** The interest rate decreased from 36.8% in 2014 to 30.4% in 2017, indicating an improvement in loan affordability over time.
- **Annual Income (annual_inc):** The annual income remained relatively stable, with a slight decline from 38.1% in 2014 to 38.0% in 2017, suggesting that income levels did not significantly impact loan eligibility during this period.
- **FICO Score Range:** The lower bound of the FICO score range increased from 26.3% in 2014 to 30.8% in 2017, indicating a potential shift towards lending to higher credit quality borrowers.
- **Debt-to-Income Ratio (dti):** The debt-to-income ratio improved slightly, decreasing from 42.8% in 2014 to 39.0% in 2017, suggesting better financial health among borrowers over time.



## 2.7 Contour Plot Comparing Risk Score vs. Debt-to-Income Ratio Before and After 2015

```{r}
# Contour PLOT

# Clone the original dataframe
dfr1 <- dfr

# Convert Application Date to Date format if not already done
dfr1$Application_Date <- as.Date(dfr1$'Application Date')

# Convert Risk_Score to numeric, handling NAs
dfr1$Risk_Score <- as.numeric(dfr1$Risk_Score)

# Convert Debt-To-Income Ratio to numeric by removing "%" and converting to decimal
dfr1$Debt_To_Income_Ratio <- as.numeric(gsub("%", "", dfr1$`Debt-To-Income Ratio`)) / 100

# Filter for application dates before and after 2015
dfr_before_2015 <- dfr1 %>% filter(Application_Date < as.Date("2015-01-01"))
dfr_after_2015 <- dfr1 %>% filter(Application_Date >= as.Date("2015-01-01"))

# Define outlier removal function using IQR
remove_outliers <- function(data) {
  # Calculate Q1, Q3, and IQR for Risk_Score
  Q1_risk <- quantile(data$Risk_Score, 0.25, na.rm = TRUE)
  Q3_risk <- quantile(data$Risk_Score, 0.75, na.rm = TRUE)
  IQR_risk <- IQR(data$Risk_Score, na.rm = TRUE)
  
  # Calculate Q1, Q3, and IQR for Debt_To_Income_Ratio
  Q1_dti <- quantile(data$Debt_To_Income_Ratio, 0.25, na.rm = TRUE)
  Q3_dti <- quantile(data$Debt_To_Income_Ratio, 0.75, na.rm = TRUE)
  IQR_dti <- IQR(data$Debt_To_Income_Ratio, na.rm = TRUE)

  # Filter data to remove outliers
  data_filtered <- data %>%
    filter(
      Risk_Score >= (Q1_risk - 1.5 * IQR_risk) & Risk_Score <= (Q3_risk + 1.5 * IQR_risk) &
      Debt_To_Income_Ratio >= (Q1_dti - 1.5 * IQR_dti) & Debt_To_Income_Ratio <= (Q3_dti + 1.5 * IQR_dti)
    )
  
  return(data_filtered)
}

# Remove outliers from both datasets
dfr_before_2015_clean <- remove_outliers(dfr_before_2015)
dfr_after_2015_clean <- remove_outliers(dfr_after_2015)

# Combine the datasets for plotting
dfr_combined <- bind_rows(
  dfr_before_2015_clean %>% mutate(Period = "Before 2015"),
  dfr_after_2015_clean %>% mutate(Period = "After 2015")
)

# Create a combined contour plot
ggplot(dfr_combined, aes(x = Risk_Score, y = Debt_To_Income_Ratio, color = Period)) +
  geom_density_2d() +
  labs(title = "Contour Plot of Risk Score vs Debt-To-Income Ratio",
       x = "Risk Score",
       y = "Debt-To-Income Ratio") +
  scale_color_manual(values = c("Before 2015" = "blue", "After 2015" = "red")) +
  theme_minimal() +
  theme(legend.title = element_blank())

# Clean up
rm(dfr_before_2015)
rm(dfr_after_2015)
rm(dfr1)
rm(dfr_before_2015_clean)
rm(dfr_after_2015_clean)

```

- **General Distribution**:  
  The contour plot shows distinct areas of concentration of rejected loan applications with varying risk scores and debt-to-income (DTI) ratios. The highest concentration for both periods is around the DTI ratio of 0.2 to 0.3 and risk scores between 600 and 700, indicating that a significant portion of rejections occurred in this range.

- **Before 2015 vs After 2015**:
    - The **blue contours** (Before 2015) indicate a denser concentration of rejected applicants with risk scores between 600 and 700 and a slightly higher DTI ratio compared to **red contours** (After 2015).
    - After 2015, the contours suggest a shift in the distribution of rejected loans, with more applicants being rejected both at lower risk scores (500-600) and higher risk scores (700+). This indicates that rejection criteria may have broadened to encompass a wider range of applicants.

- **Debt-to-Income Ratio**:  
  There is a noticeable shift in the **red contour** (After 2015) towards a higher DTI ratio (around 0.4 to 0.6) at various risk levels, compared to **blue contours** (Before 2015). This suggests that after 2015, rejected applicants tended to have higher debt burdens relative to their income, potentially reflecting either more lenient application behavior or tighter lending standards.

- **Risk Concentration Shifts**:  
    - The **After 2015** data shows a wider spread in the DTI ratio for rejected applicants with risk scores between 500 and 600, indicating that applicants with lower risk scores are increasingly being rejected for higher debt-to-income ratios.
    - In contrast, **Before 2015**, individuals with lower risk scores (below 600) who were rejected had tighter DTI ratios, suggesting that lending practices were more stringent in this category before 2015.

- **Implication on Risk**:  
  The increased spread in both the risk scores and DTI ratios for rejected loans after 2015 may indicate changes in risk assessment and rejection criteria. Lenders might have shifted their focus, possibly due to economic changes post-2015, leading to the rejection of both higher-risk and lower-risk applicants with varying debt profiles.


## 2.8 Histogram Analysis of Debt-to-Income Ratios (DTI) for Rejected Loans

```{r}
# HISTOGRAM 

# Load necessary libraries
library(ggplot2)
library(dplyr)

dfr1 <- dfr

# Ensure the Debt-To-Income Ratio is numeric
dfr1$dti <- as.numeric(gsub("%", "", dfr1$`Debt-To-Income Ratio`))  # Remove '%' and convert to numeric

# Ensure the Application Date is in Date format
dfr1$`Application Date` <- as.Date(dfr1$`Application Date`, format = "%Y-%m-%d")

# Remove NA values (if any) in Debt-To-Income Ratio and Application Date
dfr1 <- dfr1 %>% filter(!is.na(dti) & !is.na(`Application Date`))

# Define a function to remove outliers based on IQR
remove_outliers <- function(data) {
  Q1 <- quantile(data$dti, 0.25, na.rm = TRUE)  # 1st quartile (25th percentile)
  Q3 <- quantile(data$dti, 0.75, na.rm = TRUE)  # 3rd quartile (75th percentile)
  IQR <- Q3 - Q1  # Interquartile range
  lower_bound <- Q1 - 1.5 * IQR
  upper_bound <- Q3 + 1.5 * IQR
  data %>%
    filter(dti >= lower_bound & dti <= upper_bound)  # Remove outliers
}

# Apply the function to remove outliers
dfr_no_outliers <- remove_outliers(dfr1)

# Split the data into before and after 2015
dfr_before_2015 <- dfr_no_outliers %>% filter(`Application Date` < as.Date("2015-01-01"))
dfr_after_2015 <- dfr_no_outliers %>% filter(`Application Date` >= as.Date("2015-01-01"))

# Create the frequency distribution plot using ggplot
ggplot() +
  geom_histogram(data = dfr_before_2015, aes(x = dti, y = ..count.., color = "Before 2015", fill = "Before 2015"), 
                 binwidth = 1, alpha = 0.4, position = "identity") +
  geom_histogram(data = dfr_after_2015, aes(x = dti, y = ..count.., color = "After 2015", fill = "After 2015"), 
                 binwidth = 1, alpha = 0.4, position = "identity") +
  labs(title = "Frequency Distribution of Debt-To-Income Ratio (Approved Loans)",
       x = "Debt-To-Income Ratio (%)",
       y = "Frequency",
       color = "Period",
       fill = "Period") +
  theme_minimal() +
  scale_color_manual(values = c("Before 2015" = "blue", "After 2015" = "red")) +
  scale_fill_manual(values = c("Before 2015" = "blue", "After 2015" = "red")) +
  theme(legend.position = "top")

# Optional: Clean up memory
rm(dfr1)
rm(dfr_no_outliers)
rm(dfr_before_2015)
rm(dfr_after_2015)
rm(df_no_outliers)


```


- **DTI Distribution Before 2015:** The histogram for DTI values prior to 2015 shows a relatively even distribution across various DTI ranges, with no significant concentration in any specific range.
- **DTI Distribution After 2015:** 
  - A notable increase in rejections is observed for DTI values less than 5, indicating stricter lending criteria during this period.
  - Following the initial spike at low DTI values, there is a gradual decline in rejection counts as DTI increases towards 9.
  - Beyond a DTI of 9, the distribution appears to be right-skewed, suggesting that while there are fewer rejections in this range, those with very high DTIs are still facing rejections.
- **Overall Trend:** The analysis indicates a shift in lending standards after 2015, where lower DTIs are increasingly leading to loan rejections, potentially reflecting a more cautious approach by lenders to manage risk.


```{r}
rm(dfr_combined)
rm(dfr1)
```



# 3 Do the loan grades provided to each customer correlate to their loan repayment behavior based on income and loan status?

```{r preprocess_data}


# Preprocess the data
# Assuming 'loan_status' has values 'Fully Paid' and 'Charged Off'
df_final <- df %>%

  mutate(loan_status_num = ifelse(loan_status == "Fully Paid", 1, 
                                  ifelse(loan_status == "Charged Off", 0, NA)))

```


## 3.1 Loan Repayment By Grade
### 3.1.1 BAR PLOT


```{r loan_repayment_rate_by_grade, fig.width=10, fig.height=6}


# Create 'loan_status_binary' column
# Assuming "Fully Paid" = 1 and "Charged Off" = 0
df_final <- df_final %>%
  mutate(loan_status_binary = ifelse(loan_status == "Fully Paid", 1, 
                                     ifelse(loan_status == "Charged Off", 0, NA)))

# Calculate repayment rate by grade
repayment_rate <- df_final %>%
  group_by(grade) %>%
  summarise(repayment_rate = mean(loan_status_binary, na.rm = TRUE)) %>%
  mutate(grade = factor(grade, levels = c("A", "B", "C", "D", "E", "F", "G")))  # Ensure correct order

# Create the enhanced bar plot
ggplot(repayment_rate, aes(x = grade, y = repayment_rate, fill = grade)) +
  geom_bar(stat = "identity", width = 0.7) +
  geom_text(aes(label = scales::percent(repayment_rate, accuracy = 0.1)), 
            vjust = -0.5, size = 4, fontface = "bold") +
  scale_y_continuous(labels = scales::percent_format(), limits = c(0, 1)) +
  scale_fill_viridis_d() +
  labs(title = "Loan Repayment Rate by Grade",
       subtitle = "Higher grades show better repayment rates",
       x = "Loan Grade",
       y = "Repayment Rate") +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5, size = 16, face = "bold"),
    plot.subtitle = element_text(hjust = 0.5, size = 12, face = "italic"),
    axis.title = element_text(face = "bold"),
    axis.text = element_text(size = 10), 
    legend.position = "none"
  )
rm(repayment_rate)
```


-Clear correlation between grade and repayment: There's a strong positive relationship between loan grade and repayment rate. As the grade improves from G to A, the repayment rate steadily increases.

-Significant gap between top and bottom grades: The highest grade (A) has a repayment rate of 94%, while the lowest grade (G) is at 49.2% - a difference of nearly 45 percentage points. This highlights the substantial risk difference between the best and worst-rated loans.

-Steeper drops in lower grades: The decrease in repayment rate appears more pronounced between lower grades (e.g., from E to F to G) compared to higher grades. This suggests that risk increases more rapidly as loan quality declines below a certain threshold.



## 3.2 Income Distribution By Loan Grade
### 3.2.1 BOX PLOT

```{r income-distribution-boxplot}

# Function to remove outliers using IQR method
remove_outliers <- function(x) {
  qnt <- quantile(x, probs = c(0.25, 0.75), na.rm = TRUE)
  H <- 1.5 * IQR(x, na.rm = TRUE)
  x[x < (qnt[1] - H) | x > (qnt[2] + H)] <- NA
  return(x)
}

# Prepare the data and remove outliers
plot_data <- df_final %>%
  filter(!is.na(annual_inc) & annual_inc > 0) %>%
  mutate(grade = factor(grade, levels = c("A", "B", "C", "D", "E", "F", "G"))) %>%
  group_by(grade) %>%
  mutate(annual_inc_clean = remove_outliers(annual_inc)) %>%
  filter(!is.na(annual_inc_clean)) %>%
  ungroup()

# Calculate median income for annotation
median_incomes <- plot_data %>%
  group_by(grade) %>%
  summarise(median_income = median(annual_inc_clean))

# Create the enhanced boxplot without outliers
income_plot <- ggplot(plot_data, aes(x = grade, y = annual_inc_clean, fill = grade)) +
  geom_boxplot(alpha = 0.7, outlier.shape = NA) +
  geom_text(data = median_incomes, aes(y = median_income, label = scales::dollar(median_income)),
            vjust = -0.5, size = 3, fontface = "bold") +
  scale_y_log10(labels = scales::dollar_format(), 
                breaks = scales::trans_breaks("log10", function(x) 10^x),
                minor_breaks = NULL,
                limits = c(1000, NA)) +  # Set lower limit to reduce space
  scale_fill_viridis_d(option = "D", begin = 0.3, end = 0.9) +
  labs(title = "Income Distribution by Loan Grade",
       x = "Loan Grade",
       y = "Annual Income") +
  theme_minimal(base_size = 14) +
  theme(
    plot.title = element_text(hjust = 0.5, size = 22, face = "bold", margin = margin(b = 10)),
    axis.title = element_text(face = "bold", size = 16),
    axis.text = element_text(size = 12),
    legend.position = "none",
    panel.grid.major = element_line(color = "gray90"),
    panel.grid.minor = element_blank(),
    plot.background = element_rect(fill = "white", color = NA),
    panel.background = element_rect(fill = "gray98", color = NA),
    plot.margin = margin(t = 20, r = 20, b = 20, l = 20)
  ) +
  coord_cartesian(clip = "off") +
  annotate("text", x = Inf, y = Inf, label = "BOXPLOT",
           hjust = 1.1, vjust = 2, size = 4.5, fontface = "italic", color = "gray30")

# Display the plot (optional)
print(income_plot)

# Save the plot
ggsave("income_distribution_boxplot_no_outliers.png", plot = income_plot, width = 12, height = 8, dpi = 300)
rm(income_plot)
rm(median_incomes)
rm(plot_data)
```


--Higher income for better grades: There's a clear trend of higher median incomes for better loan grades. Grade A has the highest median income at $74,000, while lower grades (C through G) have lower median incomes around $60,000-$62,000.

--Income disparity narrows in lower grades: The income distributions for grades C through G are very similar, with median incomes clustered closely together. This suggests that factors other than income may be more influential in determining these lower grades.

--Wider income range for top grades: The boxplots for grades A and B appear to have larger interquartile ranges, indicating more income variability among borrowers in these categories. This could suggest that high-grade loans are accessible to a broader range of income levels, possibly due to other strong credit factors.



## 3.3 Data Preparation for Heatmap Analysis

```{r prepare-data}
# Create income brackets
# Create income brackets
df_final <- df_final %>%
  mutate(income_bracket = cut(annual_inc, 
                              breaks = quantile(annual_inc, probs = seq(0, 1, 0.2), na.rm = TRUE),
                              labels = c('Very Low', 'Low', 'Medium', 'High', 'Very High'),
                              include.lowest = TRUE))

# Reorder income_bracket factor levels
df_final$income_bracket <- factor(df_final$income_bracket, 
                              levels = c('Very High', 'High', 'Medium', 'Low', 'Very Low'))

# Calculate repayment rates
repayment_rates <- df_final %>%
  group_by(grade, income_bracket) %>%
  summarize(repayment_rate = mean(loan_status_binary, na.rm = TRUE)) %>%
  pivot_wider(names_from = income_bracket, values_from = repayment_rate)

# Display the repayment rates
print(repayment_rates)
rm(heatmap_data)
```



## 3.4 Repayment Rate by Grade and Income Bracket 
### 3.4.1 HEATMAP


```{r repayment-heatmap, fig.width=12, fig.height=8}
# Prepare data for heatmap
heatmap_data <- repayment_rates %>%
  pivot_longer(cols = -grade, names_to = "income_bracket", values_to = "repayment_rate")

# Ensure income_bracket is a factor with correct order
heatmap_data$income_bracket <- factor(heatmap_data$income_bracket, 
                                      levels = c('Very High', 'High', 'Medium', 'Low', 'Very Low'))

# Create heatmap
ggplot(heatmap_data, aes(x = income_bracket, y = grade, fill = repayment_rate)) +
  geom_tile() +
  geom_text(aes(label = scales::percent(repayment_rate, accuracy = 0.1)), color = "black") +
  scale_fill_gradientn(colors = c("yellow", "green", "blue"), 
                       labels = scales::percent_format(accuracy = 1),
                       name = "Repayment Rate") +
  labs(title = "Repayment Rate by Grade and Income Bracket",
       x = "Income Bracket",
       y = "Loan Grade") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
rm(heatmap_data)
rm(repayment_rates)
```


--Grade is the primary determinant of repayment: There's a clear vertical gradient showing that loan grade has a stronger influence on repayment rates than income. Grade A loans consistently have the highest repayment rates (91-95%) across all income brackets, while Grade G loans have the lowest (46-57%)

--Income impact varies by grade: For higher-grade loans (A-C), income has minimal effect on repayment rates. However, for lower-grade loans (D-G), there's a more noticeable positive correlation between income and repayment rates, particularly for the "Very High" income bracket.

--Surprising trend in lowest grades: Counterintuitively, for the lowest grades (F-G), the "Very High" income bracket shows higher repayment rates than some middle income brackets. This suggests that high-income borrowers with poor credit scores might be better risks than their grades suggest.



## 3.5 ANOVA Test

```{r anova_test_income_across_grades}

# Perform ANOVA to test for income differences across grades
anova_result <- aov(annual_inc ~ grade, data = df_final)

# Display the ANOVA summary
anova_summary <- summary(anova_result)

# Print the ANOVA results
cat("ANOVA test results for income differences across grades:\n")
cat(sprintf("F-statistic = %.2f, p-value = %.4f\n", 
            anova_summary[[1]]$`F value`[1], 
            anova_summary[[1]]$`Pr(>F)`[1]))
rm(anova_result)
rm(anova_summary)

```


--ANOVA test results for income differences across grades:
F-statistic = 1260.67, p-value = 0.0000

--Statistically significant difference: The extremely low p-value (0.0000) indicates there are highly statistically significant differences in income levels across loan grades. This suggests that income is a meaningful factor in determining loan grades.

--Strong relationship: The large F-statistic (1260.67) indicates a strong relationship between loan grades and income levels. This suggests that income variations explain a substantial portion of the differences between loan grades.

--Confirmation of visual trends: These results statistically confirm the visual trends observed in previous charts, where higher loan grades were associated with higher incomes. The ANOVA provides robust evidence that these income differences across grades are not due to chance.


## 3.6 Chi Square Test Grade Vs Loan Status



```{r chi_square_test}
# Create a contingency table
contingency_table <- table(df_final$grade, df_final$loan_status)

# Perform chi-square test
chi_square_result <- chisq.test(contingency_table)

# Extract results
chi2 <- chi_square_result$statistic
p_value <- chi_square_result$p.value
dof <- chi_square_result$parameter

# Print results
cat(sprintf("Chi-square test results: chi2 = %.2f, p-value = %.4f\n", 
            chi2, p_value))
cat(sprintf("Degrees of freedom: %d\n", dof))

# Print contingency table
cat("\nContingency table:\n")
print(contingency_table)

# Print expected frequencies
cat("\nExpected frequencies:\n")
print(chi_square_result$expected)
rm(chi_square_result)
```


--Highly significant relationship: The extremely low p-value (0.0000) indicates a statistically significant relationship between loan grades and loan outcomes. This suggests that loan grade is a strong predictor of loan performance.

--Grade A outperforms expectations: Comparing observed to expected frequencies, Grade A loans have far more "Fully Paid" outcomes (200,432 vs 188,974 expected) and fewer "Charged Off" outcomes (12,767 vs 48,229 expected) than expected. This underscores the lower risk associated with top-grade loans.

--Lower grades struggle more: Grades E, F, and G show higher frequencies of "Charged Off" and "Late" payments compared to their expected values. This aligns with the higher risk profile of lower-grade loans and supports the trends seen in previous analyses.



### 3.6.1 Interpretation Of chi Square Test 

```{r interpretation}
# Interpretation
cat("\nInterpretation:\n")
if (p_value < 0.05) {
  cat("The chi-square test shows a statistically significant association between Grade and Loan Status (p < 0.05).")
  cat("\nThis suggests that the loan grade is not independent of the loan status.")
} else {
  cat("The chi-square test does not show a statistically significant association between Grade and Loan Status (p >= 0.05).")
  cat("\nThis suggests that the loan grade might be independent of the loan status.")
}

# Effect size (Cramer's V)
n <- sum(contingency_table)
min_dim <- min(dim(contingency_table)) - 1
cramer_v <- sqrt(chi2 / (n * min_dim))

cat(sprintf("\n\nEffect size (Cramer's V): %.4f\n", cramer_v))
cat("Interpretation of Cramer's V:\n")
if (cramer_v < 0.1) {
  cat("Negligible association")
} else if (cramer_v < 0.3) {
  cat("Weak association")
} else if (cramer_v < 0.5) {
  cat("Moderate association")
} else {
  cat("Strong association")
}
```



## 3.7 Loan Status Distribution By Grade 
### 3.7.1 STACKED BAR CHART


```{R Loan Status Distribution by Grade}
#3. Loan Status Distribution by Grade
df_final %>%
  ggplot(aes(x = grade, fill = loan_status)) +
  geom_bar(position = "fill") +
  labs(title = "Loan Status Distribution by Grade",
       x = "Loan Grade", y = "Proportion",
       fill = "Loan Status") +
  theme_minimal() +
  scale_y_continuous(labels = scales::percent_format())

```


--Inverse relationship between grade and charge-offs: There's a clear trend of increasing charge-off rates as the loan grade decreases. Grade A loans have the lowest proportion of charge-offs, while Grade G has the highest. This reinforces the higher risk associated with lower-grade loans.

--Fully paid loans dominate higher grades: Grades A and B show a significantly higher proportion of fully paid loans compared to lower grades. This indicates that higher-grade loans are more likely to be repaid in full, aligning with their lower risk profile.

--Current loans increase in lower grades: The proportion of loans in "Current" status increases noticeably from Grade C to G. This could suggest that lower-grade loans have longer terms or that borrowers of lower-grade loans are more likely to make minimum payments rather than paying off the loan early.


#Question 4 and answers go here: (EMMA please paste your code here and complete the report. please let me know if you need any help from me)



# 5 Conclusion

Interest rates and term are the strongest predictors of loan charge offs, while loan amount does not significantly affect loan status.
The analysis highlights significant shifts in lending practices and loan applicant profiles before and after 2015. A more conservative lending approach emerged post-2015, marked by stricter criteria for risk scores and a preference for applicants with lower debt-to-income ratios and higher creditworthiness.
Loan grades strongly correlate with repayment behavior, with higher grades consistently showing better repayment rates. Income levels play a secondary role. The grading system appears to be effective in predicting loan outcomes.
In the accepted dataset, employment length significantly varies by loan grade, suggesting longer employment is linked to higher grades. In the rejected dataset, employment length has a weak but significant correlation with amount requested and a strong, significant impact on risk score, but shows no significant relationship with debt-to-income ratio.





