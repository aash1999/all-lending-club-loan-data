---
title: "Understanding Dataset"
author: "Singh Sivaram, Aakash"
date: "`r Sys.Date()`"
output:
  html_document:
    code_folding: hide
    number_sections: false
    toc: yes
    toc_depth: 3
    toc_float: yes
  pdf_document:
    toc: yes
    toc_depth: '3'
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE, comment = NA)
```

```{r init, include=F}
# include all your packages here
library(ezids)
library(data.table)
source("./HelperFunctions/fetchSubset.R")
```
```{r}
# all file paths
df_file_path = "../DataSet/filtered_accepted_2013_to_2018Q4.csv"

```

# Inspecting Dataset

```{r}
# Load Dataset
df_100 <- fetch_subset(df_file_path, col_names = c(-1), nrows = c(1, 100), chunk_size = 1e5)

```

## List of Column names 

```{r}
col_names <- names(df_100)
print(sort(col_names))
```
## \# of Observations

```{r}
nrows <- nrow(fread(df_file_path, select = 1, header = TRUE))
print(nrows)

```

## variables

```{r}
columns_to_target = c("annual_inc", "dti", "fico_range_high", "fico_range_low", "loan_amnt", 
  "int_rate", "earliest_cr_line", "revol_util", "delinq_2yrs", "pub_rec", 
  "total_acc", "open_acc", "installment", "home_ownership", 
  "verification_status", "delinq_amnt", "collections_12_mths_ex_med", 
  "chargeoff_within_12_mths", "mths_since_last_delinq", "purpose", "sub_grade", "issue_d", "addr_state","inq_last_12m","loan_status")


df <- fetch_subset(df_location = df_file_path, col_names = columns_to_target, nrows = c(1,-1))

```

```{r}
str(df)
```

```{r}
convert_to_factors <- function(df) {
  # Columns to convert to factors based on the provided list
  factor_cols <- c("home_ownership", "verification_status", 
                   "loan_status", "purpose", "addr_state","sub_grade")
  
  df[] <- lapply(names(df), function(col) {
    if (col %in% factor_cols) {
      return(as.factor(df[[col]]))
    } else if (is.character(df[[col]]) && all(!is.na(as.numeric(df[[col]][-1])))) {
      return(as.numeric(df[[col]]))
    } else {
      return(df[[col]])
    }
  })
  
  return(df)
}
df <- df[-1,]
df <- convert_to_factors(df)
str(df)
```


```{r}
# Convert specified columns to numeric

df$revol_util <- as.numeric(df$revol_util)
df$mths_since_last_delinq <- as.numeric(df$mths_since_last_delinq)
df$dti <- as.numeric(df$dti)
df$inq_last_12m <- as.numeric(df$inq_last_12m)


# Optional: Check for any warnings about NAs being introduced during coercion
if (any(is.na(df$revol_util))) {
  warning("NAs introduced in 'revol_util' during conversion.")
}
if (any(is.na(df$mths_since_last_delinq))) {
  warning("NAs introduced in 'mths_since_last_delinq' during conversion.")
}
if (any(is.na(df$dti))) {
  warning("NAs introduced in 'dti' during conversion.")
}

```
```{r}
str(df)
```

```{r}
# Count the number of NA values in each column
na_counts <- sapply(df, function(x) sum(is.na(x)))

# Print the counts of NA values
print(na_counts)

```

```{r}
# Load necessary libraries
library(corrplot)
setDT(df)  # Converts df to a data.table, if it isn't one already

# Select only numeric columns from the data table
numeric_df <- df[, .SD, .SDcols = sapply(df, is.numeric)]

# Calculate the correlation matrix
cor_matrix <- cor(numeric_df, use = "pairwise.complete.obs")

# Set plotting parameters for larger plot size
#par(cex.axis = 3, cex.lab = 3, cex.main = 3)  # Increase text size

# Create a larger plot window
options(repr.plot.width = 35, repr.plot.height = 35)  # Use this in RMarkdown or Jupyter Notebooks

# Plot the correlation matrix using corrplot
#png(filename = "mycorrplot.png", width = 1200, height = 800)
# Set plotting parameters for larger text size
corrplot(cor_matrix,
         type = "upper", 
         method = "circle", 
         addCoef.col = 0.2,  # Color for coefficients
         number.cex = 0.1,  # Size of the correlation coefficients
         tl.cex = 0.6,      # Size of the text labels for variables
         tl.col = "black",  # Color of the text labels
         cl.cex = 0.5,      # Size of the color legend text
         main = "Correlation Matrix",  # Title of the plot
         main.cex = 0.1)      # Size of the title text

# Close the device
#dev.off()
```

```{r}
# Load necessary libraries
library(lubridate)
library(dplyr)
library(ggplot2)

# Create a copy of the dataframe
df1 <- df

# Step 1: Ensure 'issue_d' is in Date format
df1$issue_d <- as.Date(df1$issue_d, format = "%Y-%m-%d")  # Adjust the format if necessary

# Step 2: Extract year and quarter from 'issue_d'
df1 <- df1 %>%
  mutate(year = year(issue_d), 
         quarter = quarter(issue_d))

# Step 3: Filter out rows with NA values in year or quarter
df1 <- df1 %>%
  filter(!is.na(year), !is.na(quarter))

# Step 4: Calculate the total number of loans per quarter
df_total_per_quarter <- df1 %>%
  group_by(year, quarter) %>%
  summarise(total_loans = n(), .groups = 'drop')  # Adding .groups = 'drop' to avoid warnings

# Step 5: Filter for 'Charged Off' loan status
df_charged_off <- df1 %>%
  filter(loan_status == "Charged Off")

# Step 6: Aggregate 'Charged Off' counts by year and quarter
df_charged_off_aggregated <- df_charged_off %>%
  group_by(year, quarter) %>%
  summarise(charged_off_count = n(), .groups = 'drop')  # Adding .groups = 'drop' to avoid warnings

# Step 7: Merge the total loan counts with the 'Charged Off' counts
df_merged <- df_charged_off_aggregated %>%
  left_join(df_total_per_quarter, by = c("year", "quarter")) %>%
  mutate(percentage = (charged_off_count / total_loans) * 100)

# Step 8: Create a Year-Quarter variable in the correct format and order
df_merged <- df_merged %>%
  mutate(Year_Quarter = paste0(year, ".", quarter)) %>%
  arrange(year, quarter)  # Arrange the data to ensure it's in the correct order

# Step 9: Convert Year_Quarter into a factor with levels in the correct chronological order
df_merged$Year_Quarter <- factor(df_merged$Year_Quarter, 
                                 levels = df_merged$Year_Quarter)

# Step 10: Create the line plot with percentage and display percentage as text on each point
ggplot(df_merged, aes(x = Year_Quarter, y = percentage, group = 1)) +
  geom_line(color = "red", size = 1) +
  geom_point(color = "red", size = 2) +
  geom_text(aes(label = sprintf("%.1f%%", percentage)), vjust = -1, size = 3.5) +  # Display percentage above points
  labs(x = "Year-Quarter", y = "Charged Off Percentage", title = "Percentage of Charged Off Loans by Year and Quarter") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```
```{r}
# Load necessary libraries
library(dplyr)
library(lubridate)

# Step 1: Verify and convert 'issue_d' to Date if necessary
df$issue_d <- as.Date(df$issue_d, format = "%Y-%m-%d")  # Adjust the format if necessary

# Step 2: Filter the dataframe for 'Charged Off' loan_status and remove NaN values
charged_off_df <- df %>%
  filter(loan_status == "Charged Off") %>%
  drop_na(issue_d)  # Ensure we have dates to work with

# Step 3: Create a new column for quarters if not already created
charged_off_df <- charged_off_df %>%
  mutate(quarter = quarter(issue_d), 
         year = year(issue_d),
         quarter_year = as.integer(format(issue_d, "%Y")) * 10 + ceiling(as.integer(format(issue_d, "%m")) / 3))

# Step 4: Check unique quarters available in the dataset
unique_quarters <- unique(charged_off_df$quarter_year)
cat("Unique quarters in the dataset:", unique_quarters, "\n")

# Step 5: Split the data into two groups: before and including Q2 2015, and after Q2 2015
before_2015_Q2 <- charged_off_df %>%
  filter(year < 2015 | (year == 2015 & quarter <= 2))

after_2015_Q2 <- charged_off_df %>%
  filter(year > 2015 | (year == 2015 & quarter > 2))

# Debug: Print sizes of both groups
cat("Number of records before and including Q2 2015:", nrow(before_2015_Q2), "\n")
cat("Number of records after Q2 2015:", nrow(after_2015_Q2), "\n")

# Proceed only if there are records in both groups
if (nrow(before_2015_Q2) > 0 && nrow(after_2015_Q2) > 0) {
  # Step 6: Identify numerical features in the filtered dataframe
  numerical_cols <- before_2015_Q2 %>%
    select_if(is.numeric) %>%
    colnames()

  # Step 7: Perform T-test for each numeric column, excluding those with zero observations in either group
  alpha <- 0.05  # Significance level
  t_test_results <- lapply(numerical_cols, function(col) {
    # Extract the two groups
    group1 <- before_2015_Q2[[col]]
    group2 <- after_2015_Q2[[col]]

    # Check if both groups have enough non-NA observations
    if (length(na.omit(group1)) > 0 && length(na.omit(group2)) > 0) {
      # Debug: Print intermediate values
      cat("\nColumn:", col, "\n")
      cat("N1:", length(na.omit(group1)), "N2:", length(na.omit(group2)), "\n")

      # Perform the t-test
      t_test_result <- t.test(group1, group2, var.equal = FALSE)  # Welch's t-test

      # Determine hypothesis status
      hypothesis_status <- ifelse(t_test_result$p.value <= alpha, "Reject H0", "Fail to Reject H0")

      return(data.frame(Feature = col, T_value = t_test_result$statistic, P_value = t_test_result$p.value, Hypothesis_Status = hypothesis_status))
    } else {
      cat("Skipping column:", col, "due to insufficient data in one of the groups.\n")
      return(NULL)  # Return NULL for insufficient data
    }
  })

  # Step 8: Remove NULL results and combine results into a dataframe
  t_test_results_df <- do.call(rbind, Filter(Negate(is.null), t_test_results))
  # Assuming you have already created t_test_results_df

  # Step 8: Combine results into a dataframe
  #t_test_results_df <- do.call(rbind, t_test_results)
  
  # Step 9: Remove unwanted features
  t_test_results_filtered <- t_test_results_df %>%
    filter(!Feature %in% c("quarter", "year", "quarter_year"))
  
  # Step 10: Print the filtered results
  print(t_test_results_filtered)


  # Step 9: Print the results
} else {
  cat("Not enough records in one of the groups to perform t-tests.\n")
}


```