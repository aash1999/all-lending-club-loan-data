---
output:
  html_document:
    code_folding: show
    number_sections: false
    toc: yes
    toc_depth: 3
    toc_float: yes
  pdf_document:
    toc: yes
    toc_depth: '3'
---

```{r setup, include=F, Echo =FALSE}
# Some of common RMD options (and the defaults) are: 
# include=T, eval=T, echo=T, results='hide'/'asis'/'markup',..., collapse=F, warning=T, message=T, error=T, cache=T, fig.width=6, fig.height=4, fig.dim=c(6,4) #inches, fig.align='left'/'center','right', 
knitr::opts_chunk$set(results="markup", warning = F, message = F)
# Can globally set option for number display format.
options(scientific=T, digits = 3) 
# options(scipen=9, digits = 3) 
```

# 2. Logistic Regression Model Performance: How do different classification models (logistic regression and classification tree) compare in their ability to predict loan charge-offs when trained on 2013-2015 data and tested on a holdout set from the same period?

```{r, echo=TRUE}

#Load Train Data
train_data <-read.csv("C:\\Users\\msyag\\OneDrive\\Documents\\Intro to Data Science\\data_2013_2015_train.csv")

#Convert Loan Status to Numeric Values \ 1= Charged Off 0 = Fully Paid
train_data$loan_status <- ifelse(train_data$loan_status == "Charged Off", 1,0)

#Load Test Data 2013-2015
test_data <-read.csv("C:\\Users\\msyag\\OneDrive\\Documents\\Intro to Data Science\\data_2013_2015_test.csv")

#Convert Loan Status to Numeric Values \ 1= Charged Off 0 = Fully Paid
test_data$loan_status <- ifelse(test_data$loan_status == "Charged Off", 1,0)

#Load Test Data 2016-2018
test_data_2 <-read.csv("C:\\Users\\msyag\\OneDrive\\Documents\\Intro to Data Science\\data_2016_2018_test.csv")

#Convert Loan Status to Numeric Values \ 1= Charged Off 0 = Fully Paid
test_data_2$loan_status <- ifelse(test_data_2$loan_status == "Charged Off", 1,0)

```

## Train the Model

Based on the logistic regression model, all predictors included in the model are statistically significant as they are less than the 0.05 confidence interval. When looking at the coefficients, there are some noticeable insights.

Loan Amount: 0.00382: A $1 increase in the loan amount slightly increases the likelihood of a loan charged off

Interest Rate: -0.608: Higher interest rates decrease the likelihood of charge-offs

GradeG: 5.209: Loans with Grade G are more likely to be charged off compared to grade A

Employment Length less than a year: -0.2635: Borrowers with less than one year of employment are less likely to be charged off. 

```{r, echo=TRUE}

#Logistic Regression Model
log_model <-glm(loan_status ~ loan_amnt + int_rate + grade + sub_grade + dti + emp_length, data = train_data, family = binomial)

#Summary of Model
summary(log_model)

```



## Evaluate the Model Using Test Data
After evaluating the model using the test data from 2013-2015, the following can be derived:

Confusion Matrix

87,927 True Negatives: Correctly predicted loans that were fully paid.

19,868 False Negatives: Correctly predicted loans that were charged off.

502 False Positives: Loans that were charged off but incorrectly predicted as fully paid.

508 True Positives: Loans that were fully paid but incorrectly charged off.



Performance Metrics

Accuracy 81.3%: The model correctly classifies 81.3% of the loans in this test set.

Sensitivity 2.49%: The model only identifies 2.49% of actual charge-offs correctly. THIS MODEL IS POOR AT DETECTING LOAN CHARGE-OFFS.

Specificity 99.43%: The model correctly identifies 99.43% of fully paid loans.



ROC Curve & AUC

AUC 0.704: On average, the model has a 70.4% chance of distinguishing between a loan that gets charged off and one that is fully paid. Overall, this model has a moderate ability to distinguish between charged off and fully paid loans when applied to unseen data from 2013-2015. 

```{r, echo=TRUE}

#libraries
library(caret)
library(pROC)

#Predict on test data
log_predict <- predict(log_model, test_data, type = "response")

#Convert Probabilities to Class 
log_predict_class <- ifelse(log_predict > 0.5, 1, 0)

#Covert Predicted and Actual to Factors with Same Levels
log_predict_class <-factor(log_predict_class, levels = c(0,1)) # Predicted Classes
test_data$loan_status <-factor(test_data$loan_status, levels = c(0,1)) # Actual Classes

#Confusion Matrix
con_matrix <- confusionMatrix(as.factor(log_predict_class), test_data$loan_status)
print(con_matrix)

#ROC Curve and AUC
roc_curve <-roc(test_data$loan_status, as.numeric(log_predict))
auc_value <- auc(roc_curve)
print(auc_value)
plot(roc_curve)

```

# 3. Logistic Regression Model Accuracy Across Timeframes: How accurately can we predict loan charge-offs for Lending Club loans issued between 2016-2018 using our 2013-2015 trained models from Question #2?

After evaluating the model using test data from 2015-2018, the following can be derived:

Confusion Matrix

60,134 True Negatives: Correctly predicted loans that were fully paid.

17,395 False Negatives: Correctly predicted loans that were charged off.

200 False Positives: Loans that were charged off but incorrectly predicted as fully paid.

197 True Positives: Loans that were fully paid but incorrectly charged off. 


Performance Metrics

Accuracy 77.4%: The model correctly classifies 77.4% of the loans in this test set.

Sensitivity 1.12%: The model only identifies 1.12% of actual charge-offs correctly. THIS MODEL IS POOR AT DETECTING LOAN CHARGE-OFFS.

Specificity 99.67%: The model correctly identifies 99.67% of fully paid loans.



ROC Curve & AUC
AUC 0.694: On average, the model has a 69.4% chance of distinguishing between a loan that gets charged off and one that is fully paid. Overall, this model has a moderate ability to distinguish between fully paid loans when applied to unseen data from 2016-2018 but could use improvement in predicting charged off loans.  

```{r, echo=TRUE}

#libraries
library(caret)
library(pROC)

#Predict on test data
log_predict_2 <- predict(log_model, test_data_2, type = "response")

#Convert Probabilities to Class 
log_predict_class_2 <- ifelse(log_predict_2 > 0.5, 1, 0)

#Covert Predicted and Actual to Factors with Same Levels
log_predict_class_2 <-factor(log_predict_class_2, levels = c(0,1)) # Predicted Classes
test_data_2$loan_status <-factor(test_data_2$loan_status, levels = c(0,1)) # Actual Classes

#Confusion Matrix
con_matrix_2 <- confusionMatrix(as.factor(log_predict_class_2), test_data_2$loan_status)
print(con_matrix_2)

#ROC Curve and AUC
roc_curve_2 <-roc(test_data_2$loan_status, as.numeric(log_predict_2))
auc_value_2 <- auc(roc_curve_2)
print(auc_value_2)
plot(roc_curve_2)
```
